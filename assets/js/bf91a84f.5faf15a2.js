"use strict";(globalThis.webpackChunksdk_mobile_doc=globalThis.webpackChunksdk_mobile_doc||[]).push([[20604],{22265(e,t,i){i.r(t),i.d(t,{assets:()=>l,contentTitle:()=>a,default:()=>c,frontMatter:()=>o,metadata:()=>n,toc:()=>d});const n=JSON.parse('{"id":"Selphi_widget_ios","title":"Selphi Widget iOS","description":"1. What is the widget?","source":"@site/docs/resources/Selphi_widget_ios.md","sourceDirName":".","slug":"/Selphi_widget_ios","permalink":"/sdk-mobile-documentation/docs/resources/Selphi_widget_ios","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"sidebar","previous":{"title":"Selphi Widget Android","permalink":"/sdk-mobile-documentation/docs/resources/Selphi_widget_android"},"next":{"title":"SelphID Resources","permalink":"/sdk-mobile-documentation/docs/resources/SelphID_resources"}}');var s=i(74848),r=i(28453);const o={},a="Selphi Widget iOS",l={},d=[{value:"1. What is the widget?",id:"1-what-is-the-widget",level:2},{value:"1.1. Minimum requirements",id:"11-minimum-requirements",level:3},{value:"2. How to integrate the widget?",id:"2-how-to-integrate-the-widget",level:2},{value:"2.1. Required libraries and configuration",id:"21-required-libraries-and-configuration",level:3},{value:"2.2. Integration steps",id:"22-integration-steps",level:3},{value:"3. Set up the widget",id:"3-set-up-the-widget",level:2},{value:"3.1. ResourcesPath",id:"31-resourcespath",level:3},{value:"3.2. Properties",id:"32-properties",level:3},{value:"3.2.1. livenessMode",id:"321-livenessmode",level:4},{value:"3.2.2. stabilizationMode",id:"322-stabilizationmode",level:4},{value:"3.2.3. qrMode",id:"323-qrmode",level:4},{value:"3.2.4. userTags",id:"324-usertags",level:4},{value:"3.2.5. locale",id:"325-locale",level:4},{value:"3.2.6. logImages",id:"326-logimages",level:4},{value:"3.2.7. tutorialFlag",id:"327-tutorialflag",level:4},{value:"3.2.8. debugMode",id:"328-debugmode",level:4},{value:"3.2.9. videoFilename",id:"329-videofilename",level:4},{value:"3.2.10. showAfterCapture",id:"3210-showaftercapture",level:4},{value:"3.2.11 extractionDuration",id:"3211-extractionduration",level:4},{value:"3.2.12 preferredOrientation",id:"3212-preferredorientation",level:4},{value:"3.2.13 cameraFlash",id:"3213-cameraflash",level:4},{value:"3.2.14 jpgQuality",id:"3214-jpgquality",level:4},{value:"3.3. Methods",id:"33-methods",level:3},{value:"3.3.0. setLicense",id:"330-setlicense",level:4},{value:"3.3.1. generateTemplateRawFromUIImage:(UIImage *)img",id:"331-generatetemplaterawfromuiimageuiimage-img",level:4},{value:"3.3.2. generateTemplateRawFromNSData:(NSData *)img",id:"332-generatetemplaterawfromnsdatansdata-img",level:4},{value:"3.3.3 widgetVersion",id:"333-widgetversion",level:4},{value:"4. Customize the widget",id:"4-customize-the-widget",level:2},{value:"4.1. Basic description",id:"41-basic-description",level:3},{value:"4.1.1. Text customization",id:"411-text-customization",level:4},{value:"4.1.2. Images customization",id:"412-images-customization",level:4},{value:"4.1.3. Colour customization",id:"413-colour-customization",level:4},{value:"4.1.4. Font customization",id:"414-font-customization",level:4},{value:"4.2. Advanced description",id:"42-advanced-description",level:3},{value:"4.2.1. Widget.xml",id:"421-widgetxml",level:4},{value:"4.2.2. String folder",id:"422-string-folder",level:4},{value:"4.2.3. Resources folder",id:"423-resources-folder",level:4},{value:"4.2.4. BACKGROUND element",id:"424-background-element",level:4},{value:"4.2.5. BUTTON element",id:"425-button-element",level:4},{value:"4.2.6. TEXT element",id:"426-text-element",level:4},{value:"4.2.7. IMAGE element",id:"427-image-element",level:4},{value:"4.2.8. VIDEO element",id:"428-video-element",level:4},{value:"5. Widget messages",id:"5-widget-messages",level:2},{value:"5.1. Protocol events",id:"51-protocol-events",level:3},{value:"5.1.1. ExtractionFinished event",id:"511-extractionfinished-event",level:4},{value:"5.1.2. ExtractionFailed event",id:"512-extractionfailed-event",level:4},{value:"5.1.3. ExtractionCancelled event",id:"513-extractioncancelled-event",level:4},{value:"5.1.4. ExtractionTimeout event",id:"514-extractiontimeout-event",level:4},{value:"5.1.5. onEvent event",id:"515-onevent-event",level:4}];function h(e){const t={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.header,{children:(0,s.jsx)(t.h1,{id:"selphi-widget-ios",children:"Selphi Widget iOS"})}),"\n",(0,s.jsx)(t.h2,{id:"1-what-is-the-widget",children:"1. What is the widget?"}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"FacePhi Selphi iOS Widget"})," is a tool designed using Objective C. With it, you will be able to carry out most of the functionalities that FacePhi offers. It is a tool designed to simplify the integration of face recognition applications technology."]}),"\n",(0,s.jsx)(t.p,{children:"Tools available in this widget are:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Internal management of the camera and the resolutions"}),"\n",(0,s.jsx)(t.li,{children:"Assistant in the authentication process"}),"\n",(0,s.jsx)(t.li,{children:"The extraction of facial patterns is transparent for the integrator"}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"11-minimum-requirements",children:"1.1. Minimum requirements"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"iOS Deployment target: 13"}),"\n"]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsx)(t.h2,{id:"2-how-to-integrate-the-widget",children:"2. How to integrate the widget?"}),"\n",(0,s.jsx)(t.h3,{id:"21-required-libraries-and-configuration",children:"2.1. Required libraries and configuration"}),"\n",(0,s.jsx)(t.p,{children:'In order to add the required libraries, from the "Build Phases" tab, you should add the following libraries in the "Embedded binaries" section:'}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["Extractor library: ",(0,s.jsx)(t.code,{children:"FPBExtractoriOS.framework"})]}),"\n",(0,s.jsxs)(t.li,{children:["Selphi Widget library: ",(0,s.jsx)(t.code,{children:"FPhiWidgetSelphi.framework"})]}),"\n",(0,s.jsxs)(t.li,{children:["Core Widget library: ",(0,s.jsx)(t.code,{children:"FPhiWidgetCore.framework"})]}),"\n",(0,s.jsxs)(t.li,{children:["ZipZap library: ",(0,s.jsx)(t.code,{children:"ZipZap.xcframework"})]}),"\n",(0,s.jsxs)(t.li,{children:["Native library: ",(0,s.jsx)(t.code,{children:"libc++.tbd"})]}),"\n"]}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["IAD version: Add additional IAD libraries\n",(0,s.jsx)(t.code,{children:"FPHILicenseManager.XCFramework"}),", ",(0,s.jsx)(t.code,{children:"IDLiveFaceCamera.XCFramework"}),", ",(0,s.jsx)(t.code,{children:"IDLiveFaceDetection.XCFramework"})," and ",(0,s.jsx)(t.code,{children:"IDLiveFaceIAD.XCFramework"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(t.p,{children:['In the "Copy bundle resources" section it is required to add the widget resources file ',(0,s.jsx)(t.code,{children:"fphi-widget-resources-SelphiLive-1.2.zip"}),"."]}),"\n",(0,s.jsx)(t.p,{children:"Since iOS 10.0, if the application uses the camera, it is required to add a usage description. To do that, the file info.plist must be modified adding the description as the value for the key NSCameraUsageDescription:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-xml",children:"    <key>NSCameraUsageDescription</key>\n    <string>Description</string>\n"})}),"\n",(0,s.jsx)(t.h3,{id:"22-integration-steps",children:"2.2. Integration steps"}),"\n",(0,s.jsx)(t.p,{children:"To integrate the widget into a controller, once you have available the required libraries, you just need to carry out the following actions:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["Import the headers file: ",(0,s.jsx)(t.code,{children:'#import "FPhiWidgetSelphi/FPhiWidgetSelphi.h"'})]}),"\n",(0,s.jsxs)(t.li,{children:["Declare a variable for the widget, type of ",(0,s.jsx)(t.code,{children:"FPhiWidget"}),": ",(0,s.jsx)(t.code,{children:"@property FPhiWidget *widget;"})]}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"Instancing the widget:"})}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-objc",children:'    // Save memory for the class and call the init method. (Constructor)\n    NSError *error = nil; \n\n    NSBundle *bundle = [NSBundle bundleForClass:[AddUserViewController class]];\n\n    _widget = [[SelphiWidgetalloc] initWithFrontCameraIfAvailable:true \n                                                        resources:[bundlepathForResource:@"fphi-widget-resources-SelphiLive-1.2" ofType:@"zip"] \n                                                         delegate:self error:&error]; \n\n    // Evaluate problems regarding camera permissions and other situations \n    if (error != nil) {\n        switch (error.code) {\n\n            case FWEUnknown:\n                NSLog(@"Widget - construction error. Unknown error");\n                break;\n\n            case FWECameraPermission:\n                NSLog(@"Widget - construction error. Camera permission denied");\n                break;\n        }\n\n        return;\n    }\n\n    // Initialize the camera and start the extraction cycle.\n    [_widget StartExtraction];\n\n    // Show the widget view and hide the actual view. \n    [self presentViewController: widget animated:true completion:nil];\n'})}),"\n",(0,s.jsxs)(t.p,{children:["During the constructor call, it is specified in its first parameter which camera is going to be used, being ",(0,s.jsx)(t.code,{children:"true"})," the value to use the front camera and ",(0,s.jsx)(t.code,{children:"false"})," the value to use the rear camera. The second parameter sets the class that implements the protocol events of the class. In the third parameter, ",(0,s.jsx)(t.code,{children:"error"})," is used to indicate a problem during the widget creation, for example, a problem regarding camera permissions."]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsx)(t.h2,{id:"3-set-up-the-widget",children:"3. Set up the widget"}),"\n",(0,s.jsx)(t.p,{children:"You can use the following properties to set up the widget:"}),"\n",(0,s.jsx)(t.h3,{id:"31-resourcespath",children:"3.1. ResourcesPath"}),"\n",(0,s.jsx)(t.p,{children:"It sets the route of the resources file that the widget will use for its graphical configuration."}),"\n",(0,s.jsx)(t.h3,{id:"32-properties",children:"3.2. Properties"}),"\n",(0,s.jsx)(t.p,{children:"The following properties are available to configure the widget:"}),"\n",(0,s.jsx)(t.h4,{id:"321-livenessmode",children:"3.2.1. livenessMode"}),"\n",(0,s.jsx)(t.p,{children:"It sets the widget liveness mode. Permitted values are:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"LMLivenessNone"}),": Indicates that must not be activated the photo detection mode in the authentication processes."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"LMLivenessMove"}),": Indicates that active liveness movement mode must be activated in the authentication processes."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"LMLivenessPassive"}),': Indicates that the liveness will be performed at server side, sending the "BestImage" or the correspondant "tokenTemplateRaw".']}),"\n"]}),"\n",(0,s.jsx)(t.h4,{id:"322-stabilizationmode",children:"3.2.2. stabilizationMode"}),"\n",(0,s.jsx)(t.p,{children:"Sets a stabilization mode prior to any authentication process in the widget. With this mode, the widget is forced not to start any process if the user is not facing forward and without moving their head."}),"\n",(0,s.jsx)(t.h4,{id:"323-qrmode",children:"3.2.3. qrMode"}),"\n",(0,s.jsx)(t.p,{children:"Indicates if the QR read wants or not to be activated precious the authentication process."}),"\n",(0,s.jsx)(t.h4,{id:"324-usertags",children:"3.2.4. userTags"}),"\n",(0,s.jsx)(t.p,{children:"It sets 4 bytes with data that may be configured by the main application and will be incorporated to the templates generated by the extractor."}),"\n",(0,s.jsx)(t.h4,{id:"325-locale",children:"3.2.5. locale"}),"\n",(0,s.jsx)(t.p,{children:'It forces the widget to use the language configuration indicated by locale parameter. This parameter accepts a language code and local identification code. If the file of the widget resources doesn\xb4t have a location for the "locale" selecting its configuration would use the language by default.'}),"\n",(0,s.jsx)(t.h4,{id:"326-logimages",children:"3.2.6. logImages"}),"\n",(0,s.jsxs)(t.p,{children:["Activate or not the return of the images list which have been captured during the execution of the extraction process. If the input parameter is ",(0,s.jsx)(t.code,{children:"true"})," will return the list of processed images. In another case, it will get back an empty list."]}),"\n",(0,s.jsx)(t.h4,{id:"327-tutorialflag",children:"3.2.7. tutorialFlag"}),"\n",(0,s.jsx)(t.p,{children:"Sets the tutorial view before any authentication process. Once the tutorial is completed the widget will continue as usual."}),"\n",(0,s.jsx)(t.h4,{id:"328-debugmode",children:"3.2.8. debugMode"}),"\n",(0,s.jsx)(t.p,{children:"It sets the debugging mode of the widget."}),"\n",(0,s.jsx)(t.h4,{id:"329-videofilename",children:"3.2.9. videoFilename"}),"\n",(0,s.jsx)(t.p,{children:"Sets the absolute path of the file name where a video of the authentication process will be recorded. The application is responsible for requesting the necessary permissions to the phone in case that path requires additional permissions. By default, the widget will not perform any recording process unless a file path is specified using this property."}),"\n",(0,s.jsx)(t.h4,{id:"3210-showaftercapture",children:"3.2.10. showAfterCapture"}),"\n",(0,s.jsx)(t.p,{children:"Enables a preview of the captured selfie prompting the user to accept it or repeat it."}),"\n",(0,s.jsx)(t.h4,{id:"3211-extractionduration",children:"3.2.11 extractionDuration"}),"\n",(0,s.jsx)(t.p,{children:"Sets the amount of time the widget will keep extracting user's facial features. The allowed values are:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"FPhiWidgetExtractionDurationShort"}),": 1 second extraction duration. (Default value)"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"FPhiWidgetExtractionDurationMedium"}),": 2 seconds extraction duration."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"FPhiWidgetExtractionDurationLong"}),": 3 seconds extraction duration."]}),"\n"]}),"\n",(0,s.jsx)(t.h4,{id:"3212-preferredorientation",children:"3.2.12 preferredOrientation"}),"\n",(0,s.jsx)(t.p,{children:"Sets the allowed orientations the widget will permit."}),"\n",(0,s.jsx)(t.p,{children:"The allowed values are:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"FPhiWidgetOrientationFullSensor"}),": All orientations allowed."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"FPhiWidgetOrientationFullSensorNoReverse"}),": All orientations but reverse portrait allowed."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"FPhiWidgetOrientationPortrait"}),": Portrait allowed. (Default)"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"FPhiWidgetOrientationLandscapeLeft"}),": Landscape left allowed."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"FPhiWidgetOrientationLandscapeRight"}),": Landscape right allowed."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"FPhiWidgetOrientationPortraitReverse"}),": Reverse portrait allowed."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"FPhiWidgetOrientationPortraitSensor"}),": Portrait and reverse portrait allowed."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"FPhiWidgetOrientationLandscapeSensor"}),": Landscape left and landscape right allowed."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"FPhiWidgetOrientationLocked"}),": All orientations allowed but the widget won't rotate dynamically."]}),"\n"]}),"\n",(0,s.jsx)(t.h4,{id:"3213-cameraflash",children:"3.2.13 cameraFlash"}),"\n",(0,s.jsx)(t.p,{children:"Enable/disable camera flash if available."}),"\n",(0,s.jsx)(t.h4,{id:"3214-jpgquality",children:"3.2.14 jpgQuality"}),"\n",(0,s.jsx)(t.p,{children:"Set jpg compression. Default value: 0.92f."}),"\n",(0,s.jsx)(t.h3,{id:"33-methods",children:"3.3. Methods"}),"\n",(0,s.jsx)(t.p,{children:"The following methods are available in the widget:"}),"\n",(0,s.jsx)(t.h4,{id:"330-setlicense",children:"3.3.0. setLicense"}),"\n",(0,s.jsx)(t.p,{children:"Sets the contents of the license that will be needed for some widget features."}),"\n",(0,s.jsx)(t.h4,{id:"331-generatetemplaterawfromuiimageuiimage-img",children:"3.3.1. generateTemplateRawFromUIImage:(UIImage *)img"}),"\n",(0,s.jsx)(t.p,{children:"Generates a templateRaw from a native Android image. This method is static so it doesn\xb4t require launching the widget to perform this operation."}),"\n",(0,s.jsx)(t.h4,{id:"332-generatetemplaterawfromnsdatansdata-img",children:"3.3.2. generateTemplateRawFromNSData:(NSData *)img"}),"\n",(0,s.jsx)(t.p,{children:"Generates a templateRaw from a byte array. This array must contain the representation of the image in jpg or png format. This method is static so it doesn\xb4t require launching the widget to perform this operation."}),"\n",(0,s.jsx)(t.h4,{id:"333-widgetversion",children:"3.3.3 widgetVersion"}),"\n",(0,s.jsx)(t.p,{children:"Returns the widget's actual version in string format. This method is static so it doesn\xb4t require launching the widget to perform this operation."}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsx)(t.h2,{id:"4-customize-the-widget",children:"4. Customize the widget"}),"\n",(0,s.jsxs)(t.p,{children:["The widget allows you to customize texts, images, font and colours. The customization is made by the .zip file provided with the widget. This zip is composed of a file titled ",(0,s.jsx)(t.code,{children:"widget.xml"})," that contains the definition of all widget screens. Each with a series of elements which allow to make the customization. The zip file also contains a folder with graphical resources and another folder with the translation of the texts."]}),"\n",(0,s.jsx)(t.h3,{id:"41-basic-description",children:"4.1. Basic description"}),"\n",(0,s.jsx)(t.h4,{id:"411-text-customization",children:"4.1.1. Text customization"}),"\n",(0,s.jsx)(t.p,{children:"The customization of texts is done editing the texts of the translation files inside the resources folder."}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{children:"    /strings/strings.es.xml\n    /strings/strings.xml\n"})}),"\n",(0,s.jsx)(t.h4,{id:"412-images-customization",children:"4.1.2. Images customization"}),"\n",(0,s.jsx)(t.p,{children:"The customization of images which the widget use it must be the images in the .zip of resources. In the zip there are 3 folders:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{children:"    /resources/163dpi\n    /resources/326dpi\n    /resources/489dpi\n"})}),"\n",(0,s.jsx)(t.p,{children:"These folders represent at different screen densities, it may be generated as many density folders as desired. In these folders are the versions of the images for each resolution."}),"\n",(0,s.jsxs)(t.p,{children:["It is necessary to add the images in all folders, once determined the optimal resolution for the device, the widget only loads the images of the folder with the selected resolution. The images are referenced from the file ",(0,s.jsx)(t.code,{children:"widget.xml"}),"."]}),"\n",(0,s.jsx)(t.h4,{id:"413-colour-customization",children:"4.1.3. Colour customization"}),"\n",(0,s.jsxs)(t.p,{children:["The customization of the colour of the buttons is done from the file ",(0,s.jsx)(t.code,{children:"widget.xml"}),". You can customize any colour of any graphical element that appears in the widget. It is simply enough to modify the colour of the property desired."]}),"\n",(0,s.jsx)(t.h4,{id:"414-font-customization",children:"4.1.4. Font customization"}),"\n",(0,s.jsxs)(t.p,{children:["The customization of the font must be placed in the folder /resources/163dpi and it can be referenced from the file ",(0,s.jsx)(t.code,{children:"widget.xml"}),".\nTo change the font of text elements is enough modifying the font property and put the name of the file."]}),"\n",(0,s.jsx)(t.p,{children:"In the following section there is more information about the content of the resources bundle and the mode to modify."}),"\n",(0,s.jsx)(t.h3,{id:"42-advanced-description",children:"4.2. Advanced description"}),"\n",(0,s.jsx)(t.h4,{id:"421-widgetxml",children:"4.2.1. Widget.xml"}),"\n",(0,s.jsx)(t.p,{children:"This file contains the definition of the properties that can be configured in the process. It is divided by navigation screens and inside of each screen tag are found all the properties that can be modified."}),"\n",(0,s.jsx)(t.p,{children:"It is possible, via code, to select the location by the local property. This parameter accepts a string with the language code desired (for example,\u201des\u201d or \u201des_ES\u201d)."}),"\n",(0,s.jsx)(t.h4,{id:"422-string-folder",children:"4.2.2. String folder"}),"\n",(0,s.jsxs)(t.p,{children:["This folder contains ",(0,s.jsx)(t.code,{children:"string.xml"})," file for each translation that may support.\nThe name must be formed as follows:"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{children:"    strings.(language).xml\n"})}),"\n",(0,s.jsxs)(t.p,{children:["Being (language) the language code. For example, ",(0,s.jsx)(t.code,{children:"strings.es.xml"})," would be the translation in Spanish, ",(0,s.jsx)(t.code,{children:"strings.en.xml"})," the translation in English, ",(0,s.jsx)(t.code,{children:"strings.es_ES.xml"})," the Spanish from Spain or ",(0,s.jsx)(t.code,{children:"strings.es_AR.xml"})," the Spanish from Argentina."]}),"\n",(0,s.jsx)(t.p,{children:"The language can be forced or let the widget select it based on the device configuration. When deciding the language to apply the following sequence is performed:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:'Searching by location code (for example, "es_AR").'}),"\n",(0,s.jsx)(t.li,{children:'If there isn\xb4t any coincidence, it is possible to search for the generical language ("es").'}),"\n",(0,s.jsx)(t.li,{children:"If there isn\xb4t any result, it is possible to use the language by default."}),"\n"]}),"\n",(0,s.jsx)(t.h4,{id:"423-resources-folder",children:"4.2.3. Resources folder"}),"\n",(0,s.jsx)(t.p,{children:"It contains the folders with all the necessary resources to be modified, divided in densities. It is mandatory to generate the images of all densities, since the widget is expecting to find them in the corresponding folder to the density of the device. It also can create new folders with the density expected."}),"\n",(0,s.jsx)(t.h4,{id:"424-background-element",children:"4.2.4. BACKGROUND element"}),"\n",(0,s.jsx)(t.p,{children:"The background element is composed of 4 segments which can be given colour independently:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"top"}),": defines the background colour of the segment or upper panel."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"middle_top"}),": defines the background colour of the segment or panel where the image of the camera is located."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"middle_bottom"}),": defines the background colour of the segment or panel where the text is located."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"bottom"}),": defines the background colour of the segment or the lower panel."]}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"It also can be configured certain properties which is used only in specific screens. Below, we list them making reference to the screens which are used:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"pagination_separator (RegistrationTips, FaceMovementTips)"}),": defines the colour separation between the lower panel and the panel under the camera."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"mirror_border_color (RegistrationTips, FaceMovementTips)"}),": defines the colour of the border of the circle which surrounds the image of the camera of the video of the registration tips. To this element also is called mirror."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"mirror border width (RegistrationTips, FaceMovementTips)"}),": defines the width of the edge of the circle which surrounds the image of the camera or the video of the registration tips. If we don\xb4t want to show the edge, we have to assign a value of 0.0 to this property."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"mirror_mist_color (StartExtractor)"}),": Defines the colour of the centre circle in the previous screen to the extraction. This colour must have always a transparency value, we should let show the image of the camera for the user can place properly before to start with the extraction. The colour format when it is included a transparency value is RGBA ( the alpha value will be indicated with the last byte)"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"mirror_color (Results)"}),": defines the background colour of the circle that show the results of the registration process."]}),"\n"]}),"\n",(0,s.jsx)(t.h4,{id:"425-button-element",children:"4.2.5. BUTTON element"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"background"}),": defines the background colour of the button"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"decorator"}),": defines the colour of the shadow of the button"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"foreground"}),": defines the colour of the font of the button in case the content is a text"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"content_type"}),": defines the type of the content of the button. There are 2 different types:","\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"RESOURCE_ID"}),": Content must contain the name of a file in the resources bundle"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"TEXT_ID"}),": Content must contain the identificator of a literal of the translations file in the resources bundle"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"content"}),": defines the content of the button, image or text"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"font"}),": defines the type of font used if the content of the button is text"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"font_size"}),": defines the size of the font if the content of the button is text"]}),"\n"]}),"\n",(0,s.jsx)(t.h4,{id:"426-text-element",children:"4.2.6. TEXT element"}),"\n",(0,s.jsx)(t.p,{children:"The text elements are used to define the graphical aspect of the texts of each widget screens. These are the properties which can be modified:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"color"}),": defines the text colour."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"font"}),": defines the type of the font used to show the text."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"font_size"}),": defines the size of the font."]}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"The results screen of the registration the two texts that define the registration quality has forced their colour to the colour of the bar that indicates the punctuation."}),"\n",(0,s.jsx)(t.h4,{id:"427-image-element",children:"4.2.7. IMAGE element"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"value"}),": defines the name of the file that contains the image to show."]}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"The image elements only have the property that defines the file where the physical image is located in the resources bundle. The images are obtained of the bundle searching in the appropriate folder according the density of the device."}),"\n",(0,s.jsx)(t.h4,{id:"428-video-element",children:"4.2.8. VIDEO element"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"value"}),": defines the name of the file that contains the video to show."]}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"The video elements only have the property that defines the file where the physical video is located in the resources bundle."}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsx)(t.h2,{id:"5-widget-messages",children:"5. Widget messages"}),"\n",(0,s.jsxs)(t.p,{children:["The communication from the widget to the application once the facial characteristics extraction is finished is done through events. In order to indicate which class will implement this method (implements the protocol), you should indicate it in the second parameter of the init method (in this example, ",(0,s.jsx)(t.code,{children:"self"}),"):"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-objc",children:'    _widget = [[SelphiWidgetalloc] initWithFrontCameraIfAvailable:true \n                resources:[bundlepathForResource:@"fphi-widget-resources-SelphiLive-1.2" ofType:@"zip"] \n                delegate:self error:&error]; \n'})}),"\n",(0,s.jsxs)(t.p,{children:["In this case, ",(0,s.jsx)(t.code,{children:"self"})," indicates that it will be implemented in the same class that the call is done."]}),"\n",(0,s.jsx)(t.h3,{id:"51-protocol-events",children:"5.1. Protocol events"}),"\n",(0,s.jsx)(t.p,{children:"The iOS Widget provided by FacePhi is responsible for performing the extraction of the facial features of the user, and thus will generate a facial template representative of the user."}),"\n",(0,s.jsx)(t.h4,{id:"511-extractionfinished-event",children:"5.1.1. ExtractionFinished event"}),"\n",(0,s.jsx)(t.p,{children:"It is executed when an extraction process ends."}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-objc",children:"    (void) ExtractionFinished {\n        // Elements available during the extraction\n        FPhiWidgetExtractionData *results = _widget.results;\n        FPBExtractionResult *result = results.result;\n\n        // Template obtained during the extraction\n        NSData *templateRaw = [result getTemplateRaw];\n\n        // Best Image of the process\n        UIImage *bestImage = results.bestImage.image;\n\n        // Best Image of the process cropped at the face coordinates\n        UIImage *bestImageCropped = results.bestImageCropped.image;\n    }\n"})}),"\n",(0,s.jsxs)(t.p,{children:["the ",(0,s.jsx)(t.code,{children:"results"})," object contains these fields"]}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"templateRaw"}),": It retrieves the generated raw template after the extraction process."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"images"}),": If ",(0,s.jsx)(t.code,{children:"logImages"}),' flag is set, it retrieves the images obtained during the extraction process.The images are retrieved from highest to lowest by its "facial score" so the best of the image of the extraction process is found in the 0 position of array.']}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"bestImage"}),": Returns the best image extracted from the authentication process. This image is the original size image taken from the camera."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"bestImageCropped"}),': Returns a cropped image centered on the user\'s face. This image is obtained from the "bestImage". This is the image that should be used as a characteristic image of the user who carried out the process as an \u2018avatar\u2019.']}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"livenessDiagnostic"}),": It retrieves the final diagnostic of the liveness process."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"qrData"}),": It retrieves the data of QR codes captured."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"iadBundle"}),": It retrieves the encrypted data from the injection attack detection analysis."]}),"\n"]}),"\n",(0,s.jsx)(t.h4,{id:"512-extractionfailed-event",children:"5.1.2. ExtractionFailed event"}),"\n",(0,s.jsx)(t.p,{children:"This event is executed when any problem happened while extracting."}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-objc",children:"    (void)ExtractionFailed:(NSError *) error {\n    }\n"})}),"\n",(0,s.jsx)(t.h4,{id:"513-extractioncancelled-event",children:"5.1.3. ExtractionCancelled event"}),"\n",(0,s.jsx)(t.p,{children:"This event is executed when the user cancels the process manually by pressing on \u2018Cancel\u2019."}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-objc",children:"    (void)ExtractionCancelled {\n    }\n"})}),"\n",(0,s.jsx)(t.h4,{id:"514-extractiontimeout-event",children:"5.1.4. ExtractionTimeout event"}),"\n",(0,s.jsx)(t.p,{children:"This event is executed when a maximum allowed time is reached without detecting a face."}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-objc",children:"    (void)ExtractionTimeout {\n    }\n"})}),"\n",(0,s.jsx)(t.h4,{id:"515-onevent-event",children:"5.1.5. onEvent event"}),"\n",(0,s.jsx)(t.p,{children:"This event allows our widget to send information to the main application about important events that occur during the execution."}),"\n",(0,s.jsx)(t.p,{children:"This method receives as parameters the time of the event, encoded as UnixTime in milliseconds, the type of event and the information of the event associated with this particular event. There are mainly 3 types of events:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Events about view changes or widget status changes."}),"\n",(0,s.jsx)(t.li,{children:"User events such as button clicks or swipe movements."}),"\n",(0,s.jsx)(t.li,{children:"Events about the process that is currently in progress. These events can be about errors not detecting a face, about wrong movements or even not following the indications about the current process."}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"With these events we can comunicate important data to analyze user behavior while using our technology"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-objc",children:"    (void)onEvent:(NSDate *)time type:(NSString *)type info:(NSString *)info {\n    }\n"})})]})}function c(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}},28453(e,t,i){i.d(t,{R:()=>o,x:()=>a});var n=i(96540);const s={},r=n.createContext(s);function o(e){const t=n.useContext(r);return n.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),n.createElement(r.Provider,{value:t},e.children)}}}]);