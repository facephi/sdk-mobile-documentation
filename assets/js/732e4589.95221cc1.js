"use strict";(globalThis.webpackChunksdk_mobile_doc=globalThis.webpackChunksdk_mobile_doc||[]).push([[85274],{97514(e,n,i){i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>h,frontMatter:()=>r,metadata:()=>t,toc:()=>a});const t=JSON.parse('{"id":"Video_Id_Component","title":"Video Identification","description":"1. Introduction","source":"@site/docs/android/Video_Id_Component.md","sourceDirName":".","slug":"/Video_Id_Component","permalink":"/sdk-mobile-documentation/docs/android/next/Video_Id_Component","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"sidebar","previous":{"title":"Video Call","permalink":"/sdk-mobile-documentation/docs/android/next/Video_Call_Component"},"next":{"title":"Video Recording","permalink":"/sdk-mobile-documentation/docs/android/next/Video_Recording_Component"}}');var o=i(74848),d=i(28453);const r={},s="Video Identification",c={},a=[{value:"1. Introduction",id:"1-introduction",level:2},{value:"2. Dependency",id:"2-dependency",level:2},{value:"3. Available Controllers",id:"3-available-controllers",level:2},{value:"4. Quick Launch",id:"4-quick-launch",level:2},{value:"5. Basic Configuration",id:"5-basic-configuration",level:2},{value:"6. Receiving the Result",id:"6-receiving-the-result",level:2},{value:"6.1 Handling Errors",id:"61-handling-errors",level:3},{value:"6.2 Handling Success \u2013 <code>data</code>",id:"62-handling-success--data",level:3},{value:"6.2.1 <code>frontDocumentData</code>",id:"621-frontdocumentdata",level:4},{value:"6.2.2 <code>backDocumentData</code>",id:"622-backdocumentdata",level:4},{value:"6.2.3 <code>faceImage</code>",id:"623-faceimage",level:4},{value:"6.2.4 <code>ocrMap</code>",id:"624-ocrmap",level:4},{value:"6.2.5 <code>ocrDiagnostic</code>",id:"625-ocrdiagnostic",level:4},{value:"6.2.6 <code>matchingSidesScore</code>",id:"626-matchingsidesscore",level:4},{value:"6.2.7 <code>documentType</code>",id:"627-documenttype",level:4},{value:"6.2.8 <code>personalData</code>",id:"628-personaldata",level:4},{value:"6.2.9 <code>speechText</code>",id:"629-speechtext",level:4},{value:"6.2.10 <code>faceImageTokenized</code>",id:"6210-faceimagetokenized",level:4},{value:"7. Advanced Information",id:"7-advanced-information",level:2},{value:"7.1 Advanced Component Configuration",id:"71-advanced-component-configuration",level:3},{value:"7.1.1. url",id:"711-url",level:4},{value:"7.1.2. apiKey",id:"712-apikey",level:4},{value:"7.1.3. tenantId",id:"713-tenantid",level:4},{value:"7.1.4. sectionTime",id:"714-sectiontime",level:4},{value:"7.1.5. mode",id:"715-mode",level:4},{value:"7.1.6. timeoutServerConnection",id:"716-timeoutserverconnection",level:4},{value:"7.1.7. sectionTimeout",id:"717-sectiontimeout",level:4},{value:"7.1.8. autoFaceDetection",id:"718-autofacedetection",level:4},{value:"7.1.9. debug",id:"719-debug",level:4},{value:"7.1.10. countryFilter",id:"7110-countryfilter",level:4},{value:"7.1.11. documentFilter",id:"7111-documentfilter",level:4},{value:"7.1.12. speechText",id:"7112-speechtext",level:4},{value:"7.1.13. ocrValidations",id:"7113-ocrvalidations",level:4},{value:"7.1.14. ocrMaxWarnings",id:"7114-ocrmaxwarnings",level:4},{value:"7.1.15. maxRetries",id:"7115-maxretries",level:4},{value:"8. Component Customization",id:"8-component-customization",level:2},{value:"8.1 Texts",id:"81-texts",level:3},{value:"8.2 Animations",id:"82-animations",level:3},{value:"8.3 External Views",id:"83-external-views",level:3},{value:"9. Logs",id:"9-logs",level:2}];function l(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,d.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"video-identification",children:"Video Identification"})}),"\n",(0,o.jsx)(n.h2,{id:"1-introduction",children:"1. Introduction"}),"\n",(0,o.jsxs)(n.p,{children:["Video identification is performed with the ",(0,o.jsx)(n.strong,{children:"VideoId Component"}),"."]}),"\n",(0,o.jsx)(n.p,{children:"This component is responsible for recording a user identifying themselves by presenting their face and identity document."}),"\n",(0,o.jsx)(n.p,{children:"Its main processes include:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Internal management of camera, microphone, and permissions"}),"\n",(0,o.jsx)(n.li,{children:"Connection to video services"}),"\n",(0,o.jsx)(n.li,{children:"OCR reading and document capture"}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:["Refer to the ",(0,o.jsx)(n.a,{href:"./Mobile_SDK",children:"Quickstart"})," section for basic SDK integration steps. This guide adds details specific to launching this component."]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"2-dependency",children:"2. Dependency"}),"\n",(0,o.jsx)(n.p,{children:"The component-specific dependency is:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-java",children:'implementation "com.facephi.androidsdk:video_id_component:$version"\n'})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"3-available-controllers",children:"3. Available Controllers"}),"\n",(0,o.jsxs)(n.table,{children:[(0,o.jsx)(n.thead,{children:(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.th,{children:(0,o.jsx)(n.strong,{children:"Controller"})}),(0,o.jsx)(n.th,{children:(0,o.jsx)(n.strong,{children:"Description"})})]})}),(0,o.jsxs)(n.tbody,{children:[(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"VideoIdController"}),(0,o.jsx)(n.td,{children:"Main controller for video identification"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"SignatureVideoIdController"}),(0,o.jsx)(n.td,{children:"Controller for signing a process with a capture"})]})]})]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"4-quick-launch",children:"4. Quick Launch"}),"\n",(0,o.jsx)(n.p,{children:"Once the SDK is initialized and a new operation has been created, launch the component using any of its controllers:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-java",children:'val response = SDKController.launch(\n    VideoIdController(\n        VideoIdConfigurationData(...)\n    )\n)\n\nwhen (response) {\n    is SdkResult.Error   -> Napier.d("ERROR - ${response.error.name}")\n    is SdkResult.Success -> response.data\n}\n'})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"5-basic-configuration",children:"5. Basic Configuration"}),"\n",(0,o.jsxs)(n.p,{children:["To launch the component, create a ",(0,o.jsx)(n.code,{children:"VideoIdConfigurationData"})," object with the following field:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-java",children:"VideoIdConfigurationData(\n    mode = VideoIdMode.DOCUMENT_FRONT_BACK\n)\n"})}),"\n",(0,o.jsxs)(n.p,{children:["Available ",(0,o.jsx)(n.code,{children:"VideoIdMode"})," values:"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"VideoIdMode.ONLY_FACE"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"VideoIdMode.FACE_DOCUMENT_FRONT"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"VideoIdMode.FACE_DOCUMENT_FRONT_BACK"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"VideoIdMode.DOCUMENT_FRONT"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"VideoIdMode.DOCUMENT_FRONT_BACK"})}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"6-receiving-the-result",children:"6. Receiving the Result"}),"\n",(0,o.jsxs)(n.p,{children:["The launch returns an ",(0,o.jsx)(n.code,{children:"SdkResult"}),", allowing you to differentiate between success and error:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-java",children:'when (response) {\n    is SdkResult.Error   -> Napier.d("ERROR - ${response.error}")\n    is SdkResult.Success -> response.data\n}\n'})}),"\n",(0,o.jsx)(n.h3,{id:"61-handling-errors",children:"6.1 Handling Errors"}),"\n",(0,o.jsxs)(n.p,{children:["Errors are returned as a ",(0,o.jsx)(n.code,{children:"VideoIdError"})," object. Possible values include:"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"APPLICATION_CONTEXT_ERROR: Required application context is null"}),"\n",(0,o.jsx)(n.li,{children:"CANCEL_BY_USER: User has cancelled the process"}),"\n",(0,o.jsx)(n.li,{children:"CANCEL_LAUNCH: A general cancellation of the SDK has been done."}),"\n",(0,o.jsx)(n.li,{children:"COMPONENT_LICENSE_ERROR: The license of the component is not correct"}),"\n",(0,o.jsx)(n.li,{children:"EMPTY_LICENSE: License String is empty"}),"\n",(0,o.jsx)(n.li,{children:"FACE_DETECTION_TIMEOUT: No face detected"}),"\n",(0,o.jsx)(n.li,{children:"FETCH_DATA_ERROR: Error in the result collection"}),"\n",(0,o.jsx)(n.li,{children:"FLOW_ERROR: Error in the flow process"}),"\n",(0,o.jsx)(n.li,{children:"INITIALIZATION_ERROR: Initialisation error"}),"\n",(0,o.jsx)(n.li,{children:"MANAGER_NOT_INITIALIZED: Managers are nil"}),"\n",(0,o.jsx)(n.li,{children:"NETWORK_CONNECTION: Error in internet connection"}),"\n",(0,o.jsx)(n.li,{children:"NO_DATA_ERROR: Input data is null"}),"\n",(0,o.jsx)(n.li,{children:"OPERATION_NOT_CREATED: No operation in progress"}),"\n",(0,o.jsx)(n.li,{children:"PERMISSION_DENIED: User has denied permissions"}),"\n",(0,o.jsx)(n.li,{children:"SOCKET_ERROR: Error in the connection of services"}),"\n",(0,o.jsx)(n.li,{children:"TIMEOUT: Timeout in the process"}),"\n",(0,o.jsx)(n.li,{children:"VIDEO_ERROR: Error in video processing"}),"\n",(0,o.jsx)(n.li,{children:"VIDEO_RECORDING_ACTIVE: Cannot start because the video recording process is active."}),"\n"]}),"\n",(0,o.jsxs)(n.h3,{id:"62-handling-success--data",children:["6.2 Handling Success \u2013 ",(0,o.jsx)(n.code,{children:"data"})]}),"\n",(0,o.jsxs)(n.p,{children:["On success (",(0,o.jsx)(n.code,{children:"SdkResult.Success"}),"), you receive a ",(0,o.jsx)(n.code,{children:"VideoIdResult"})," object. Images are returned as ",(0,o.jsx)(n.code,{children:"SdkImage"}),"; extract the bitmap via ",(0,o.jsx)(n.code,{children:"image.bitmap"}),". To convert to Base64:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-kotlin",children:"Base64.encodeToString(this.toByteArray(), Base64.NO_WRAP)\n"})}),"\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.code,{children:"VideoIdResult"})," includes the following fields:"]}),"\n",(0,o.jsxs)(n.h4,{id:"621-frontdocumentdata",children:["6.2.1 ",(0,o.jsx)(n.code,{children:"frontDocumentData"})]}),"\n",(0,o.jsx)(n.p,{children:"Data for the front of the document, including:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"documentImage: Image of the document"}),"\n",(0,o.jsx)(n.li,{children:"documentFullImage: Complete frame"}),"\n",(0,o.jsx)(n.li,{children:"documentFaceImage: If a face has been found in the document, the image of the face is returned."}),"\n",(0,o.jsx)(n.li,{children:"iqaOverExposure: Numerical value between 0 and 1 indicating the level of overexposure of the image; a high value\nsuggests that the image is too bright, which may make the document difficult to read."}),"\n",(0,o.jsx)(n.li,{children:"iqaReadable: Numerical value between 0 and 1 indicating the readability of the text in the document; higher values\nimply that the text is clearer and easier to recognise."}),"\n",(0,o.jsx)(n.li,{children:"iqaSharpness: Numerical value between 0 and 1 indicating the sharpness of the document image; higher values\nreflect a more focused image, which improves the data extraction capability."}),"\n",(0,o.jsx)(n.li,{children:"documentFaceImageTokenized: If a face has been found in the document, the tokenized image of the face is returned."}),"\n"]}),"\n",(0,o.jsxs)(n.h4,{id:"622-backdocumentdata",children:["6.2.2 ",(0,o.jsx)(n.code,{children:"backDocumentData"})]}),"\n",(0,o.jsxs)(n.p,{children:["Data for the back of the document, including the same fields as ",(0,o.jsx)(n.code,{children:"frontDocumentData"}),"."]}),"\n",(0,o.jsxs)(n.h4,{id:"623-faceimage",children:["6.2.3 ",(0,o.jsx)(n.code,{children:"faceImage"})]}),"\n",(0,o.jsx)(n.p,{children:"User\u2019s face recording from the first section of the process."}),"\n",(0,o.jsxs)(n.h4,{id:"624-ocrmap",children:["6.2.4 ",(0,o.jsx)(n.code,{children:"ocrMap"})]}),"\n",(0,o.jsx)(n.p,{children:"Map of OCR-extracted values from the document."}),"\n",(0,o.jsxs)(n.h4,{id:"625-ocrdiagnostic",children:["6.2.5 ",(0,o.jsx)(n.code,{children:"ocrDiagnostic"})]}),"\n",(0,o.jsx)(n.p,{children:"Dictionary with the OCR diagnostic of the document. The keys are the\nfields to be validated and the values are instances of OcrDiagnostic."}),"\n",(0,o.jsx)(n.p,{children:"OCR diagnostic extracted from the document."}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"OK: The OCR is correct."}),"\n",(0,o.jsx)(n.li,{children:"NOT_FOUND: The OCR key is not found."}),"\n",(0,o.jsx)(n.li,{children:"TOLERANCE_ERROR: The OCR is not correct."}),"\n",(0,o.jsx)(n.li,{children:"WARNING: The OCR is not correct, but it is a warning because is an optional field."}),"\n"]}),"\n",(0,o.jsxs)(n.h4,{id:"626-matchingsidesscore",children:["6.2.6 ",(0,o.jsx)(n.code,{children:"matchingSidesScore"})]}),"\n",(0,o.jsx)(n.p,{children:"Similarity score (0.0\u20131.0) between front and back document data."}),"\n",(0,o.jsxs)(n.h4,{id:"627-documenttype",children:["6.2.7 ",(0,o.jsx)(n.code,{children:"documentType"})]}),"\n",(0,o.jsx)(n.p,{children:"Detected document type."}),"\n",(0,o.jsxs)(n.h4,{id:"628-personaldata",children:["6.2.8 ",(0,o.jsx)(n.code,{children:"personalData"})]}),"\n",(0,o.jsx)(n.p,{children:"Subset of extracted personal data:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"issuer"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"documentNumber"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"issueDate"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"expiryDate"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"name"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"surname"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"fullName"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"gender"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"birthDate"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"birthPlace"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"nationality"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"address"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"nfcKey"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"numSupport"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"mrz"})}),"\n"]}),"\n",(0,o.jsxs)(n.h4,{id:"629-speechtext",children:["6.2.9 ",(0,o.jsx)(n.code,{children:"speechText"})]}),"\n",(0,o.jsx)(n.p,{children:"Text the user must speak during the video recording."}),"\n",(0,o.jsxs)(n.h4,{id:"6210-faceimagetokenized",children:["6.2.10 ",(0,o.jsx)(n.code,{children:"faceImageTokenized"})]}),"\n",(0,o.jsx)(n.p,{children:"Tokenized face image captured during the process."}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"7-advanced-information",children:"7. Advanced Information"}),"\n",(0,o.jsx)(n.p,{children:"This section provides advanced configuration options for the VideoId Component."}),"\n",(0,o.jsx)(n.h3,{id:"71-advanced-component-configuration",children:"7.1 Advanced Component Configuration"}),"\n",(0,o.jsxs)(n.p,{children:["List of fields in ",(0,o.jsx)(n.code,{children:"VideoIdConfigurationData"}),"."]}),"\n",(0,o.jsxs)(n.p,{children:["The fields included in the configuration ",(0,o.jsx)(n.strong,{children:"(url, apiKey, tenantId)"}),",\nusually ",(0,o.jsx)(n.strong,{children:"do not need to be reported"})," as they are filled internally\nthrough the licence used."]}),"\n",(0,o.jsxs)(n.p,{children:["These fields are usually ",(0,o.jsx)(n.strong,{children:"reported only"})," when the server is\n",(0,o.jsx)(n.strong,{children:"OnPremise"}),"."]}),"\n",(0,o.jsx)(n.h4,{id:"711-url",children:"7.1.1. url"}),"\n",(0,o.jsx)(n.p,{children:"Path to the video socket"}),"\n",(0,o.jsx)(n.h4,{id:"712-apikey",children:"7.1.2. apiKey"}),"\n",(0,o.jsx)(n.p,{children:"ApiKey needed for connection to the video socket"}),"\n",(0,o.jsx)(n.h4,{id:"713-tenantid",children:"7.1.3. tenantId"}),"\n",(0,o.jsx)(n.p,{children:"Tenant identifier referring to the current client, required for the\nconnection to the video service."}),"\n",(0,o.jsx)(n.h4,{id:"714-sectiontime",children:"7.1.4. sectionTime"}),"\n",(0,o.jsx)(n.p,{children:"Indicates the duration of sections with associated time (facial capture and camera change)."}),"\n",(0,o.jsx)(n.h4,{id:"715-mode",children:"7.1.5. mode"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"ONLY_FACE: process is necessarily performed by showing only the\nface."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"FACE_DOCUMENT_FRONT: The process is performed using both the face\nand the front of the identity document."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"FACE_DOCUMENT_FRONT_BACK: The process is performed using the face,\nthe front of the identity document and the back of the document."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"DOCUMENT_FRONT: The process extracts data only from the front side of the document."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"DOCUMENT_FRONT_BACK: The process extracts only the information from the entire document."}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h4,{id:"716-timeoutserverconnection",children:"7.1.6. timeoutServerConnection"}),"\n",(0,o.jsx)(n.p,{children:"Maximum timeout in ms for server response."}),"\n",(0,o.jsx)(n.h4,{id:"717-sectiontimeout",children:"7.1.7. sectionTimeout"}),"\n",(0,o.jsx)(n.p,{children:"Maximum time allowed to complete a section (in ms)."}),"\n",(0,o.jsx)(n.h4,{id:"718-autofacedetection",children:"7.1.8. autoFaceDetection"}),"\n",(0,o.jsx)(n.p,{children:"Enables/Disables automatic face detection."}),"\n",(0,o.jsx)(n.h4,{id:"719-debug",children:"7.1.9. debug"}),"\n",(0,o.jsx)(n.p,{children:"Enables the display of additional information useful for the diagnosis and monitoring of internal behaviour."}),"\n",(0,o.jsx)(n.h4,{id:"7110-countryfilter",children:"7.1.10. countryFilter"}),"\n",(0,o.jsx)(n.p,{children:"It allows to restrict processing to a specific set of countries by accepting an array of strings representing the aliases in ISO3 format (3-letter code according to ISO 3166-1 standard)."}),"\n",(0,o.jsx)(n.h4,{id:"7111-documentfilter",children:"7.1.11. documentFilter"}),"\n",(0,o.jsx)(n.p,{children:"Allows to restrict the types of documents accepted during capture. Possible values are:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:'"IDC": ID Card'}),"\n",(0,o.jsx)(n.li,{children:'"PSP": Passport'}),"\n",(0,o.jsx)(n.li,{children:'"DLI": Driver License'}),"\n",(0,o.jsx)(n.li,{children:'"VIS": Visa'}),"\n",(0,o.jsx)(n.li,{children:'"FOC": Foreign Card'}),"\n",(0,o.jsx)(n.li,{children:'"INV": Invoice'}),"\n",(0,o.jsx)(n.li,{children:'"CUS": Custom Document'}),"\n"]}),"\n",(0,o.jsx)(n.h4,{id:"7112-speechtext",children:"7.1.12. speechText"}),"\n",(0,o.jsx)(n.p,{children:"Text to be spoken by the user during the recording of the video."}),"\n",(0,o.jsx)(n.h4,{id:"7113-ocrvalidations",children:"7.1.13. ocrValidations"}),"\n",(0,o.jsx)(n.p,{children:"Dictionary with the OCR validations to be performed. The keys are the fields to be validated and the values are instances of OcrValidationValue."}),"\n",(0,o.jsx)(n.p,{children:"OcrValidationValue has the following fields:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"value: The value to be validated."}),"\n",(0,o.jsxs)(n.li,{children:["tolerance: The tolerance level for the validation.","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"STRICT: Strict validation."}),"\n",(0,o.jsx)(n.li,{children:"LOW_TOLERANCE: Low tolerance validation."}),"\n",(0,o.jsx)(n.li,{children:"MEDIUM_TOLERANCE: Medium tolerance validation."}),"\n",(0,o.jsx)(n.li,{children:"HIGH_TOLERANCE: High tolerance validation."}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["validationType: The type of validation to be performed.","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"OPTIONAL: Optional validation."}),"\n",(0,o.jsx)(n.li,{children:"REQUIRED: Required validation."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h4,{id:"7114-ocrmaxwarnings",children:"7.1.14. ocrMaxWarnings"}),"\n",(0,o.jsx)(n.p,{children:"Maximum number of warnings allowed in the OCR validation."}),"\n",(0,o.jsx)(n.h4,{id:"7115-maxretries",children:"7.1.15. maxRetries"}),"\n",(0,o.jsx)(n.p,{children:"Maximum number of retries allowed for the OCR validation. 3 is the default value."}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"8-component-customization",children:"8. Component Customization"}),"\n",(0,o.jsxs)(n.p,{children:["Beyond SDK-level settings (",(0,o.jsx)(n.a,{href:"./Mobile_SDK_advanced",children:"Advanced Settings"}),"), this component allows interface customization."]}),"\n",(0,o.jsx)(n.h3,{id:"81-texts",children:"8.1 Texts"}),"\n",(0,o.jsx)(n.p,{children:"If you want to modify the SDK texts, you would have to include the\nfollowing XML file in the client application, and modify the value of\neach String to the desired one."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-xml",children:'    \x3c!-- Waiting --\x3e\n    <string name="video_id_component_text_waiting_agent_title">Video ID</string>\n    \x3c!-- Process --\x3e\n    <string name="video_id_component_document_front_message">Place the front of your document within the frame</string>\n    <string name="video_id_component_document_front_message_readable">Keep the front of your document within the frame</string>\n    <string name="video_id_component_document_front_message_not_readable">Bring the front of your document closer to the frame</string>\n    <string name="video_id_component_document_front_message_finish">Front of document captured correctly</string>\n    <string name="video_id_component_document_back_message">Now place the back of your document</string>\n    <string name="video_id_component_document_back_message_readable">Keep the back of your document within the frame</string>\n    <string name="video_id_component_document_back_message_not_readable">Bring the back of your document closer to the frame</string>\n    <string name="video_id_component_document_back_message_finish">Back of document captured correctly</string>\n    <string name="video_id_component_switch_camera_message">Prepare your document while the camera is being changed</string>\n    <string name="video_id_component_init_message_face_content_desc">Place your face in front of the camera and start recording</string>\n    <string name="video_id_component_init_message_face_docu_content_desc">Place your face and your document in front of the camera and start recording</string>\n    <string name="video_id_component_speech_message">I (name and surname) accept the terms and conditions</string>\n    <string name="video_id_component_speech_say_out_loud">Say out loud </string>\n    <string name="video_id_component_finish_message">Video recording\\ncompleted</string>\n    <string name="video_id_component_record_init_button">Start recording</string>\n    <string name="video_id_component_ready_button">Ready</string>\n    <string name="video_id_component_first_message_face">Place your face within the frame</string>\n    <string name="video_id_component_first_message_multiple_face">Multiple faces detected. Place only your face within the frame. </string>\n    \x3c!-- Diagnostic --\x3e\n    <string name="video_id_component_restart">Repeat recording</string>\n    <string name="video_id_component_timeout_title">Time exceeded</string>\n    <string name="video_id_component_timeout_desc">We apologize. The capture could not be made</string>\n    <string name="video_id_component_face_timeout_desc">Please place yourself on the marks to start recording.</string>\n    <string name="video_id_component_internal_error_title">There was a technical problem</string>\n    <string name="video_id_component_internal_error_desc">We apologize. The capture could not be made</string>\n\n'})}),"\n",(0,o.jsx)(n.h3,{id:"82-animations",children:"8.2 Animations"}),"\n",(0,o.jsx)(n.p,{children:"If you want to modify the animations (lottie) of the SDK you would have to include the animations with the same name in the res/raw/ folder of the application."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-text",children:"video_id_anim_doc_and_face.json\nvideo_id_anim_face.json\nvideo_id_anim_loading.json\n"})}),"\n",(0,o.jsx)(n.h3,{id:"83-external-views",children:"8.3 External Views"}),"\n",(0,o.jsx)(n.p,{children:"It is possible to completely modify the component screens while maintaining their functionality and navigation. To do so, the following interfaces must be implemented:"}),"\n",(0,o.jsx)(n.p,{children:"Error diagnosis screen:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-kotlin",children:"\ninterface IVideoIdErrorDiagnosticView {\n    @Composable\n    fun Content(\n        error: VideoIdError,\n        onRetry: () -> Unit,\n        onClose: () -> Unit,\n    )\n}\n\n"})}),"\n",(0,o.jsx)(n.p,{children:'Once the classes that implement the interfaces have been created, the "customViews" parameter can be added at component launch to be used in the SDK.'}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"9-logs",children:"9. Logs"}),"\n",(0,o.jsxs)(n.p,{children:["Filter console logs for this component with: ",(0,o.jsx)(n.code,{children:'"VIDEO_ID:"'})]})]})}function h(e={}){const{wrapper:n}={...(0,d.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},28453(e,n,i){i.d(n,{R:()=>r,x:()=>s});var t=i(96540);const o={},d=t.createContext(o);function r(e){const n=t.useContext(d);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),t.createElement(d.Provider,{value:n},e.children)}}}]);