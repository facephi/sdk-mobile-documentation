"use strict";(self.webpackChunksdk_mobile_doc=self.webpackChunksdk_mobile_doc||[]).push([[2195],{998:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>c,contentTitle:()=>t,default:()=>u,frontMatter:()=>l,metadata:()=>r,toc:()=>o});var i=a(4848),s=a(8453);const l={},t=void 0,r={id:"Verification_Component",title:"Verification_Component",description:"3. Iniciar nueva operaci\xf3n",source:"@site/i18n/es/docusaurus-plugin-content-docs-android/current/Verification_Component.md",sourceDirName:".",slug:"/Verification_Component",permalink:"/sdk-mobile-documentation/es/docs/android/next/Verification_Component",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"sidebar",previous:{title:"Flow Component",permalink:"/sdk-mobile-documentation/es/docs/android/next/Flow_Component"},next:{title:"Changelog",permalink:"/sdk-mobile-documentation/es/docs/android/next/Changelog"}},c={},o=[{value:"3. Iniciar nueva operaci\xf3n",id:"3-iniciar-nueva-operaci\xf3n",level:2},{value:"4. Controladores disponibles",id:"4-controladores-disponibles",level:2},{value:"5. Funciones",id:"5-funciones",level:2},{value:"5.1. Liveness",id:"51-liveness",level:3},{value:"5.1.1. Liveness con imagen",id:"511-liveness-con-imagen",level:4},{value:"5.1.2. Liveness con <em>template</em>",id:"512-liveness-con-template",level:4},{value:"5.2. Matching",id:"52-matching",level:3},{value:"5.2.1. Matching de dos im\xe1genes faciales en base 64",id:"521-matching-de-dos-im\xe1genes-faciales-en-base-64",level:4},{value:"5.2.2. Matching de dos <em>templates</em>",id:"522-matching-de-dos-templates",level:4},{value:"5.2.3. Matching de una imagen facial en base 64 con un <em>template</em>",id:"523-matching-de-una-imagen-facial-en-base-64-con-un-template",level:4},{value:"5.2.4. Matching de una imagen facial en base 64 con la imagen del documento",id:"524-matching-de-una-imagen-facial-en-base-64-con-la-imagen-del-documento",level:4},{value:"5.2.5. Matching de una <em>template</em> con la imagen del documento",id:"525-matching-de-una-template-con-la-imagen-del-documento",level:4},{value:"5.3. Voz",id:"53-voz",level:3},{value:"5.3.1. Enroll",id:"531-enroll",level:4},{value:"5.3.2. Authentication",id:"532-authentication",level:4},{value:"6. Extensiones y otras funciones del SDK",id:"6-extensiones-y-otras-funciones-del-sdk",level:2}];function d(e){const n={code:"code",em:"em",h2:"h2",h3:"h3",h4:"h4",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h2,{id:"3-iniciar-nueva-operaci\xf3n",children:"3. Iniciar nueva operaci\xf3n"}),"\n",(0,i.jsxs)(n.p,{children:["Cuando se desea realizar una determinada operaci\xf3n, para generar la\ninformaci\xf3n asociada correctamente en la plataforma deber\xe1 ejecutarse\npreviamente el comando ",(0,i.jsx)(n.strong,{children:"newOperation"}),"."]}),"\n",(0,i.jsxs)(n.p,{children:["Este comando debe haberse ejecutado ",(0,i.jsx)(n.strong,{children:"anteriormente al lanzamiento del\ncomponente"}),"."]}),"\n",(0,i.jsxs)(n.p,{children:["Para saber m\xe1s acerca de c\xf3mo iniciar una nueva operaci\xf3n, se recomienda\nconsultar la documentaci\xf3n de ",(0,i.jsx)("a",{href:"ES_Mobile_SDK","data-linked-resource-id":"2605285492","data-linked-resource-version":"11","data-linked-resource-type":"page",children:(0,i.jsx)("strong",{children:(0,i.jsx)("u",{children:"Android Mobile\nSDK"})})}),", en el que se detalla y explica en qu\xe9 consiste\neste proceso."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"4-controladores-disponibles",children:"4. Controladores disponibles"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:(0,i.jsx)(n.strong,{children:"Controlador"})}),(0,i.jsx)(n.th,{children:(0,i.jsx)(n.strong,{children:"Descripci\xf3n"})})]})}),(0,i.jsx)(n.tbody,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"VerificationController"}),(0,i.jsx)(n.td,{children:"Controlador principal de Verificaciones"})]})})]}),"\n",(0,i.jsx)(n.p,{children:"Para hacer uso del mismo:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"  val verificationController = VerificationController(context)\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"5-funciones",children:"5. Funciones"}),"\n",(0,i.jsx)(n.p,{children:"Los procesos de verificaci\xf3n se dividen en:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Liveness"}),"\n",(0,i.jsx)(n.li,{children:"Matching"}),"\n",(0,i.jsx)(n.li,{children:"Voz"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsxs)(n.strong,{children:["El ",(0,i.jsx)(n.em,{children:"extraData"})," ser\xe1 necesario cuando se utilice el componente de tracking"]})}),"\n",(0,i.jsx)(n.h3,{id:"51-liveness",children:"5.1. Liveness"}),"\n",(0,i.jsx)(n.p,{children:"Proceso para verificar que la imagen corresponde a una persona viva."}),"\n",(0,i.jsx)(n.p,{children:"La respuesta de estas funciones tendr\xe1 los siguientes datos:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:" data class LivenessResponse(\n    val diagnostic: String? = null,\n    val trackingMessage: String? = null,\n    val trackingStatus: Int? = null,\n    val validTimeStamp: Boolean? = null\n)\n"})}),"\n",(0,i.jsx)(n.h4,{id:"511-liveness-con-imagen",children:"5.1.1. Liveness con imagen"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"  /api/v1/selphid/passive-liveness/evaluate\n"})}),"\n",(0,i.jsx)(n.p,{children:"Para utilizar este servicio se debe enviar la bestImage de Selphi en base64 y el extra data."}),"\n",(0,i.jsx)(n.p,{children:"Datos de entrada:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:" data class LivenessWithImageRequest(\n    var image: String,\n    var extraData: String\n)\n"})}),"\n",(0,i.jsx)(n.p,{children:"Funci\xf3n:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"fun livenessWithImage(\n        request: LivenessWithImageRequest,\n        baseUrl: String,\n    ): VerificationsResult<LivenessResponse>\n"})}),"\n",(0,i.jsxs)(n.h4,{id:"512-liveness-con-template",children:["5.1.2. Liveness con ",(0,i.jsx)(n.em,{children:"template"})]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:" /api/v1/selphid/passive-liveness/evaluate/token\n"})}),"\n",(0,i.jsx)(n.p,{children:"Para utilizar este servicio se debe enviar la bestImageTokenized de Selphi  y el extra data."}),"\n",(0,i.jsx)(n.p,{children:"Datos de entrada:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"data class LivenessWithTemplateRequest(\n    var tokenImage: String,\n    var extraData: String\n)\n"})}),"\n",(0,i.jsx)(n.p,{children:"Funci\xf3n:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"fun livenessWithTemplate(\n        request: LivenessWithTemplateRequest,\n        baseUrl: String,\n    ): VerificationsResult<LivenessResponse>\n"})}),"\n",(0,i.jsx)(n.h3,{id:"52-matching",children:"5.2. Matching"}),"\n",(0,i.jsx)(n.p,{children:"Proceso para verificar que las dos im\xe1genes corresponden a la mispa persona."}),"\n",(0,i.jsx)(n.p,{children:"La respuesta de estas funciones tendr\xe1 los siguientes datos:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:" data class MatchingResponse(\n    val authStatus: String? = null,\n    val similarity: Double? = null,\n    val trackingMessage: String? = null,\n    val trackingStatus: Int? = null,\n    val validTimeStamp: Boolean? = null\n)\n"})}),"\n",(0,i.jsx)(n.h4,{id:"521-matching-de-dos-im\xe1genes-faciales-en-base-64",children:"5.2.1. Matching de dos im\xe1genes faciales en base 64"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:" /api/v1/selphid/authenticate-facial/images\n"})}),"\n",(0,i.jsx)(n.p,{children:"Para utilizar este servicio se deben enviar dos im\xe1genes en base 64 y el extra data."}),"\n",(0,i.jsx)(n.p,{children:"Datos de entrada:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"data class MatchingFacialImagesRequest(\n    var image1: String,\n    var image2: String,\n    var extraData: String\n)\n"})}),"\n",(0,i.jsx)(n.p,{children:"Funci\xf3n:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:" fun matchingFacialImages(\n        request: MatchingFacialImagesRequest,\n        baseUrl: String,\n    ): VerificationsResult<MatchingResponse>\n"})}),"\n",(0,i.jsxs)(n.h4,{id:"522-matching-de-dos-templates",children:["5.2.2. Matching de dos ",(0,i.jsx)(n.em,{children:"templates"})]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:" /api/v1/selphid/authenticate-facial/templates\n"})}),"\n",(0,i.jsx)(n.p,{children:"Para utilizar este servicio se deben enviar dos im\xe1genes cifradas y en base 64. Si se\nutilizan los datos extra\xeddos de Selphi se puede hacer uso tanto del string bestImageTokenized\ncomo de la templateRaw convertida."}),"\n",(0,i.jsx)(n.p,{children:"Datos de entrada:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"data class MatchingFacialTemplatesRequest(\n    var faceTemplate1: String,\n    var faceTemplate2: String,\n    var extraData: String\n)\n"})}),"\n",(0,i.jsx)(n.p,{children:"Funci\xf3n:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"fun matchingFacialTemplates(\n        request: MatchingFacialTemplatesRequest,\n        baseUrl: String,\n    ): VerificationsResult<MatchingResponse>\n"})}),"\n",(0,i.jsxs)(n.h4,{id:"523-matching-de-una-imagen-facial-en-base-64-con-un-template",children:["5.2.3. Matching de una imagen facial en base 64 con un ",(0,i.jsx)(n.em,{children:"template"})]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:" /api/v1/selphid/authenticate-facial/image/template\n"})}),"\n",(0,i.jsx)(n.p,{children:"Mezcla de los dos casos anteriores."}),"\n",(0,i.jsx)(n.p,{children:"Datos de entrada:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"data class MatchingFacialImageWithTemplateRequest(\n    var faceTemplate: String,\n    var image: String,\n    var extraData: String\n)\n"})}),"\n",(0,i.jsx)(n.p,{children:"Funci\xf3n:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"fun matchingFacialImageWithTemplate(\n        request: MatchingFacialImageWithTemplateRequest,\n        baseUrl: String,\n    ): VerificationsResult<MatchingResponse>\n"})}),"\n",(0,i.jsx)(n.h4,{id:"524-matching-de-una-imagen-facial-en-base-64-con-la-imagen-del-documento",children:"5.2.4. Matching de una imagen facial en base 64 con la imagen del documento"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:" /api/v1/selphid/authenticate-facial/document/face-image\n"})}),"\n",(0,i.jsx)(n.p,{children:"Para utilizar este servicio se deben enviar, por un lado, la imagen cifrada extra\xedda del\nocumento con SelphID tokenFaceImage y, por otro, la bestImage en base 64 extra\xedda de Selphi."}),"\n",(0,i.jsx)(n.p,{children:"Datos de entrada:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"data class MatchingDocumentWithFaceImageRequest(\n    var image: String,\n    var documentTemplate: String,\n    var extraData: String\n)\n"})}),"\n",(0,i.jsx)(n.p,{children:"Funci\xf3n:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"fun matchingDocumentWithFaceImage(\n        request: MatchingDocumentWithFaceImageRequest,\n        baseUrl: String,\n    ): VerificationsResult<MatchingResponse>\n"})}),"\n",(0,i.jsxs)(n.h4,{id:"525-matching-de-una-template-con-la-imagen-del-documento",children:["5.2.5. Matching de una ",(0,i.jsx)(n.em,{children:"template"})," con la imagen del documento"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:" /api/v1/selphid/authenticate-facial/document/face-template\n"})}),"\n",(0,i.jsx)(n.p,{children:"Para utilizar este servicio se deben enviar, por un lado, la imagen cifrada extra\xedda del documento\ncon SelphID tokenFaceImage y, por otro, si se utilizan los datos extra\xeddos de Selphi, tanto del string\nbestImageTokenized como de la templateRaw convertida a Base64."}),"\n",(0,i.jsx)(n.p,{children:"Datos de entrada:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"data class MatchingDocumentWithFaceTemplateRequest(\n    var faceTemplate: String,\n    var documentTemplate: String,\n    var extraData: String\n)\n"})}),"\n",(0,i.jsx)(n.p,{children:"Funci\xf3n:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"fun matchingDocumentWithFaceTemplate(\n        request: MatchingDocumentWithFaceTemplateRequest,\n        baseUrl: String,\n    ): VerificationsResult<MatchingResponse>\n"})}),"\n",(0,i.jsx)(n.h3,{id:"53-voz",children:"5.3. Voz"}),"\n",(0,i.jsx)(n.p,{children:"Proceso para hacer verificaciones sobre los audios cifrados extra\xeddos del componente de voz."}),"\n",(0,i.jsx)(n.h4,{id:"531-enroll",children:"5.3.1. Enroll"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"/api/v1/enrollment\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Este servicio recibe los audios cifrados y responde con la ",(0,i.jsx)(n.em,{children:"template"})," creada a partir de ellos."]}),"\n",(0,i.jsx)(n.p,{children:"Datos de entrada:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"data class VoiceEnrollRequest(\n    var audios: Array<String>,\n    var checkLiveness: Boolean = true,\n    var livenessThreshold: Double = 0.5,\n    var minimumSnrDb: Int = 8,\n    var minimumSpeechDurationMs: Int = 1500,\n    var minimumSpeechRelativeLenght: Float? = null,\n    var maximumMultipleSpeakersDetectorScore: Int? = null,\n    var extraData: String\n)\n"})}),"\n",(0,i.jsx)(n.p,{children:"Funci\xf3n:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"fun voiceEnroll(\n        request: VoiceEnrollRequest,\n        baseUrl: String = RepositoryConstants.BASE_VOICE_URL,\n    ): VerificationsResult<EnrollResponse>\n"})}),"\n",(0,i.jsx)(n.p,{children:"Datos de salida:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"data class EnrollResponse(\n    val template: String? = null,\n    val validateAudiosResult: List<ValidateAudiosResult>? = null,\n    val operationResult: Int? = null,\n    val templateType: String? = null,\n)\n"})}),"\n",(0,i.jsx)(n.h4,{id:"532-authentication",children:"5.3.2. Authentication"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"/api/v1/authentication\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Este servicio verifica si un audio cifrado corresponde con una ",(0,i.jsx)(n.em,{children:"template"})," obtenida con el servicio de ",(0,i.jsx)(n.em,{children:"enroll"}),"."]}),"\n",(0,i.jsx)(n.p,{children:"Datos de entrada:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"data class VoiceAuthenticationRequest(\n    var audio: String,\n    var template: String,\n    var livenessThreshold: Double = 0.5,\n    var minimumSnrDb: Int = 8,\n    var minimumSpeechDurationMs: Int = 1500,\n    var extraData: String\n)\n"})}),"\n",(0,i.jsx)(n.p,{children:"Funci\xf3n:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"fun voiceAuthentication(\n        request: VoiceAuthenticationRequest,\n        baseUrl: String,\n    ): VerificationsResult<VoiceAuthenticationResponse>\n"})}),"\n",(0,i.jsx)(n.p,{children:"Datos de salida:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"data class VoiceAuthenticationResponse(\n    val match: Boolean? = null,\n    val matchingScore: Float? = null,\n    val livenessScore: Float? = null,\n    val operationResult: Int? = null,\n    val trackingMessage: String? = null,\n)\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"6-extensiones-y-otras-funciones-del-sdk",children:"6. Extensiones y otras funciones del SDK"}),"\n",(0,i.jsx)(n.p,{children:"Para las conversiones se pueden hacer uso de las siguientes extemsiones:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"fun Bitmap.toBase64(): String? {\n    return Base64.encodeToString(this.toByteArray(), Base64.NO_WRAP)\n}\n\n\nfun Bitmap.toByteArray(quality: Int = 95): ByteArray {\n    ByteArrayOutputStream().apply {\n        compress(Bitmap.CompressFormat.JPEG, quality, this)\n        return toByteArray()\n    }\n}\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Para la obtenci\xf3n del ",(0,i.jsx)(n.em,{children:"extraData"})," necesario para las operaciones se puede utilizar la siguiente funci\xf3n (se puede usar viewModelScope.launch o CoroutineScope(Dispatchers.IO).launch):"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:'private fun getExtraData(output: (String) -> Unit)\n  {\n      viewModelScope.launch {\n        when (val result = SDKController.launch(ExtraDataController())) {\n            is SdkResult.Success -> output(result.data)\n            is SdkResult.Error -> output("")\n        }\n      }\n  }\n'})}),"\n",(0,i.jsx)(n.p,{children:"Para la obtenci\xf3n de una imagen cifrada y en base 64 en el SDK Mobile se puede a utilizar la\nsiguiente funci\xf3n (se puede usar viewModelScope.launch o CoroutineScope(Dispatchers.IO).launch):"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:'private fun getTemplateFromImage(\n  sdkImage: SdkImage, \n  output: (String) -> Unit) \n  {\n      viewModelScope.launch {\n        when (val result = SDKController.launch(RawTemplateController(sdkImage))) {\n            is SdkResult.Success -> output(result.data)\n            is SdkResult.Error -> output("")\n        }\n      }\n  }\n'})})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,a)=>{a.d(n,{R:()=>t,x:()=>r});var i=a(6540);const s={},l=i.createContext(s);function t(e){const n=i.useContext(l);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:t(e.components),i.createElement(l.Provider,{value:n},e.children)}}}]);